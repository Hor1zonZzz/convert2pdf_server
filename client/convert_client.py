#!/usr/bin/env python3
"""
Convert2PDF Client - ç®€å•æ˜“ç”¨çš„PDFè½¬æ¢å®¢æˆ·ç«¯

ä½¿ç”¨ç¤ºä¾‹:
    # åŸºç¡€ç”¨æ³•
    client = ConvertClient("192.168.1.100", 7758)
    results = await client.convert_directory("/path/to/documents")
    
    # é«˜çº§ç”¨æ³•
    results = await client.convert_directory(
        "/path/to/documents", 
        output_dir="/path/to/output",
        max_workers=10,
        recursive=True
    )
"""

import asyncio
import os
import pathlib
from typing import Dict, List, Optional, Union
import aiohttp
import aiofiles
from dataclasses import dataclass
from datetime import datetime
import logging
from tqdm.asyncio import tqdm
import time
import json


@dataclass
class ConvertResult:
    """è½¬æ¢ç»“æœæ•°æ®ç±»"""
    original_file: str
    status: str
    converted_url: Optional[str] = None
    error: Optional[str] = None
    elapsed_time: float = 0.0


class ConvertClient:
    """PDFè½¬æ¢å®¢æˆ·ç«¯
    
    æä¾›ç®€å•æ˜“ç”¨çš„æ–‡ä»¶æ‰¹é‡è½¬æ¢åŠŸèƒ½ï¼Œæ”¯æŒï¼š
    - è‡ªåŠ¨è¿æ¥æ£€æµ‹
    - å¼‚æ­¥å¹¶å‘å¤„ç†
    - æ™ºèƒ½é‡è¯•æœºåˆ¶
    - è¿›åº¦å®æ—¶æ˜¾ç¤º
    - ç»“æœå¯¼å‡º
    """
    
    def __init__(
        self, 
        host: str = "localhost", 
        port: int = 7758,
        timeout: int = 300,
        max_retries: int = 3,
        retry_delay: float = 1.0
    ):
        """åˆå§‹åŒ–å®¢æˆ·ç«¯
        
        Args:
            host: æœåŠ¡ç«¯IPåœ°å€
            port: æœåŠ¡ç«¯ç«¯å£
            timeout: è¯·æ±‚è¶…æ—¶æ—¶é—´(ç§’)
            max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
            retry_delay: é‡è¯•é—´éš”(ç§’)
        """
        self.host = host
        self.port = port
        self.base_url = f"http://{host}:{port}"
        self.timeout = aiohttp.ClientTimeout(total=timeout)
        self.max_retries = max_retries
        self.retry_delay = retry_delay
        self.supported_types: List[str] = []
        
        # é…ç½®æ—¥å¿—
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        )
        self.logger = logging.getLogger(__name__)
        
    async def __aenter__(self):
        """å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨å…¥å£"""
        await self.connect()
        return self
        
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        """å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨å‡ºå£"""
        pass
    
    async def connect(self) -> bool:
        """è¿æ¥åˆ°æœåŠ¡ç«¯å¹¶è·å–åŸºæœ¬ä¿¡æ¯
        
        Returns:
            bool: è¿æ¥æ˜¯å¦æˆåŠŸ
        """
        try:
            # å¥åº·æ£€æŸ¥
            await self._health_check()
            
            # è·å–æ”¯æŒçš„æ–‡ä»¶ç±»å‹
            await self._get_supported_types()
            
            self.logger.info(f"âœ… æˆåŠŸè¿æ¥åˆ°æœåŠ¡ç«¯ {self.base_url}")
            self.logger.info(f"ğŸ“‹ æ”¯æŒ {len(self.supported_types)} ç§æ–‡ä»¶æ ¼å¼")
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ è¿æ¥æœåŠ¡ç«¯å¤±è´¥: {e}")
            return False
    
    async def _health_check(self):
        """å¥åº·æ£€æŸ¥"""
        async with aiohttp.ClientSession(timeout=self.timeout) as session:
            async with session.get(f"{self.base_url}/health") as response:
                if response.status != 200:
                    raise ConnectionError(f"æœåŠ¡ç«¯å¥åº·æ£€æŸ¥å¤±è´¥: {response.status}")
                result = await response.json()
                if result.get("status") != "ok":
                    raise ConnectionError("æœåŠ¡ç«¯çŠ¶æ€å¼‚å¸¸")
    
    async def _get_supported_types(self):
        """è·å–æ”¯æŒçš„æ–‡ä»¶ç±»å‹"""
        async with aiohttp.ClientSession(timeout=self.timeout) as session:
            async with session.get(f"{self.base_url}/get_supported_file_types") as response:
                if response.status != 200:
                    raise ConnectionError(f"è·å–æ”¯æŒæ–‡ä»¶ç±»å‹å¤±è´¥: {response.status}")
                result = await response.json()
                self.supported_types = result.get("supported_file_types", [])
    
    def is_supported_file(self, file_path: Union[str, pathlib.Path]) -> bool:
        """æ£€æŸ¥æ–‡ä»¶æ˜¯å¦æ”¯æŒè½¬æ¢
        
        Args:
            file_path: æ–‡ä»¶è·¯å¾„
            
        Returns:
            bool: æ˜¯å¦æ”¯æŒ
        """
        if not self.supported_types:
            return False
        
        file_path = pathlib.Path(file_path)
        return file_path.suffix.lower() in self.supported_types
    
    async def convert_file(self, file_path: Union[str, pathlib.Path]) -> ConvertResult:
        """è½¬æ¢å•ä¸ªæ–‡ä»¶
        
        Args:
            file_path: æ–‡ä»¶è·¯å¾„
            
        Returns:
            ConvertResult: è½¬æ¢ç»“æœ
        """
        file_path = pathlib.Path(file_path)
        start_time = time.time()
        
        if not file_path.exists():
            return ConvertResult(
                original_file=str(file_path),
                status="error",
                error="æ–‡ä»¶ä¸å­˜åœ¨",
                elapsed_time=time.time() - start_time
            )
        
        if not self.is_supported_file(file_path):
            return ConvertResult(
                original_file=str(file_path),
                status="error", 
                error=f"ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: {file_path.suffix}",
                elapsed_time=time.time() - start_time
            )
        
        # æ‰§è¡Œè½¬æ¢ï¼ˆå¸¦é‡è¯•ï¼‰
        for attempt in range(self.max_retries + 1):
            try:
                result = await self._do_convert_file(file_path)
                result.elapsed_time = time.time() - start_time
                return result
                
            except Exception as e:
                if attempt < self.max_retries:
                    # æŒ‡æ•°é€€é¿é‡è¯•
                    wait_time = self.retry_delay * (2 ** attempt)
                    self.logger.warning(f"è½¬æ¢å¤±è´¥ (å°è¯• {attempt + 1}/{self.max_retries + 1}): {e}")
                    self.logger.info(f"ç­‰å¾… {wait_time:.1f}ç§’åé‡è¯•...")
                    await asyncio.sleep(wait_time)
                else:
                    return ConvertResult(
                        original_file=str(file_path),
                        status="error",
                        error=f"è½¬æ¢å¤±è´¥ (å·²é‡è¯•{self.max_retries}æ¬¡): {str(e)}",
                        elapsed_time=time.time() - start_time
                    )
    
    async def _do_convert_file(self, file_path: pathlib.Path) -> ConvertResult:
        """æ‰§è¡Œæ–‡ä»¶è½¬æ¢çš„æ ¸å¿ƒé€»è¾‘"""
        async with aiohttp.ClientSession(timeout=self.timeout) as session:
            # å‡†å¤‡multipart form data
            data = aiohttp.FormData()
            
            # è¯»å–æ–‡ä»¶å¹¶æ·»åŠ åˆ°è¡¨å•
            async with aiofiles.open(file_path, 'rb') as f:
                file_content = await f.read()
                data.add_field('file', file_content, filename=file_path.name)
            
            # å‘é€è½¬æ¢è¯·æ±‚
            async with session.post(f"{self.base_url}/convert", data=data) as response:
                response_text = await response.text()
                
                if response.status == 200:
                    result = await response.json()
                    return ConvertResult(
                        original_file=str(file_path),
                        status=result.get("status", "unknown"),
                        converted_url=result.get("converted_url")
                    )
                else:
                    # å°è¯•è§£æé”™è¯¯ä¿¡æ¯
                    try:
                        error_data = json.loads(response_text)
                        error_msg = error_data.get("error", f"HTTP {response.status}")
                    except:
                        error_msg = f"HTTP {response.status}: {response_text}"
                    
                    raise Exception(error_msg)
    
    def find_files(
        self, 
        directory: Union[str, pathlib.Path], 
        recursive: bool = True
    ) -> List[pathlib.Path]:
        """æŸ¥æ‰¾ç›®å½•ä¸­æ”¯æŒçš„æ–‡ä»¶
        
        Args:
            directory: ç›®å½•è·¯å¾„
            recursive: æ˜¯å¦é€’å½’æœç´¢å­ç›®å½•
            
        Returns:
            List[pathlib.Path]: æ”¯æŒçš„æ–‡ä»¶åˆ—è¡¨
        """
        directory = pathlib.Path(directory)
        if not directory.exists() or not directory.is_dir():
            self.logger.error(f"ç›®å½•ä¸å­˜åœ¨æˆ–ä¸æ˜¯ç›®å½•: {directory}")
            return []
        
        files = []
        pattern = "**/*" if recursive else "*"
        
        for file_path in directory.glob(pattern):
            if file_path.is_file() and self.is_supported_file(file_path):
                files.append(file_path)
        
        self.logger.info(f"ğŸ“ åœ¨ {directory} ä¸­æ‰¾åˆ° {len(files)} ä¸ªå¯è½¬æ¢æ–‡ä»¶")
        return files
    
    async def convert_directory(
        self,
        directory: Union[str, pathlib.Path],
        output_dir: Optional[Union[str, pathlib.Path]] = None,
        max_workers: int = 5,
        recursive: bool = True,
        save_results: bool = True
    ) -> List[ConvertResult]:
        """æ‰¹é‡è½¬æ¢ç›®å½•ä¸­çš„æ–‡ä»¶
        
        Args:
            directory: è¾“å…¥ç›®å½•
            output_dir: ç»“æœä¿å­˜ç›®å½•ï¼ˆå¯é€‰ï¼‰
            max_workers: æœ€å¤§å¹¶å‘æ•°
            recursive: æ˜¯å¦é€’å½’æœç´¢
            save_results: æ˜¯å¦ä¿å­˜ç»“æœåˆ°JSONæ–‡ä»¶
            
        Returns:
            List[ConvertResult]: è½¬æ¢ç»“æœåˆ—è¡¨
        """
        # ç¡®ä¿å·²è¿æ¥
        if not self.supported_types:
            if not await self.connect():
                raise ConnectionError("æ— æ³•è¿æ¥åˆ°æœåŠ¡ç«¯")
        
        # æŸ¥æ‰¾æ–‡ä»¶
        files = self.find_files(directory, recursive)
        if not files:
            self.logger.warning("æ²¡æœ‰æ‰¾åˆ°å¯è½¬æ¢çš„æ–‡ä»¶")
            return []
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        if output_dir:
            output_dir = pathlib.Path(output_dir)
            output_dir.mkdir(parents=True, exist_ok=True)
        
        # åˆ›å»ºè¿›åº¦æ¡
        progress_bar = tqdm(total=len(files), desc="è½¬æ¢è¿›åº¦", unit="æ–‡ä»¶")
        
        # åˆ›å»ºä»»åŠ¡é˜Ÿåˆ—
        semaphore = asyncio.Semaphore(max_workers)
        results = []
        
        async def convert_with_progress(file_path):
            async with semaphore:
                result = await self.convert_file(file_path)
                progress_bar.update(1)
                progress_bar.set_postfix({
                    'æˆåŠŸ': sum(1 for r in results if r.status == 'success'),
                    'å¤±è´¥': sum(1 for r in results if r.status == 'error'),
                    'å½“å‰': file_path.name[:20]
                })
                return result
        
        # æ‰§è¡Œå¹¶å‘è½¬æ¢
        start_time = time.time()
        tasks = [convert_with_progress(file_path) for file_path in files]
        results = await asyncio.gather(*tasks)
        
        progress_bar.close()
        total_time = time.time() - start_time
        
        # ç»Ÿè®¡ç»“æœ
        success_count = sum(1 for r in results if r.status == 'success')
        error_count = len(results) - success_count
        
        self.logger.info(f"\nğŸ“Š è½¬æ¢å®Œæˆ!")
        self.logger.info(f"   æ€»è®¡: {len(results)} ä¸ªæ–‡ä»¶")
        self.logger.info(f"   æˆåŠŸ: {success_count} ä¸ª")
        self.logger.info(f"   å¤±è´¥: {error_count} ä¸ª")
        self.logger.info(f"   ç”¨æ—¶: {total_time:.1f} ç§’")
        self.logger.info(f"   å¹³å‡: {total_time/len(results):.1f} ç§’/æ–‡ä»¶")
        
        # ä¿å­˜ç»“æœ
        if save_results:
            await self._save_results(results, output_dir or pathlib.Path(directory).parent)
        
        return results
    
    async def _save_results(
        self, 
        results: List[ConvertResult], 
        output_dir: pathlib.Path
    ):
        """ä¿å­˜è½¬æ¢ç»“æœåˆ°JSONæ–‡ä»¶"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        result_file = output_dir / f"convert_results_{timestamp}.json"
        
        # è½¬æ¢ä¸ºå¯åºåˆ—åŒ–çš„æ ¼å¼
        serializable_results = []
        for result in results:
            serializable_results.append({
                "original_file": result.original_file,
                "status": result.status,
                "converted_url": result.converted_url,
                "error": result.error,
                "elapsed_time": result.elapsed_time
            })
        
        # å†™å…¥æ–‡ä»¶
        async with aiofiles.open(result_file, 'w', encoding='utf-8') as f:
            await f.write(json.dumps(serializable_results, indent=2, ensure_ascii=False))
        
        self.logger.info(f"ğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: {result_file}")


# ä¾¿æ·å‡½æ•°
async def convert_directory_simple(
    host: str,
    port: int,
    directory: str,
    max_workers: int = 5
) -> List[ConvertResult]:
    """ç®€åŒ–çš„ç›®å½•è½¬æ¢å‡½æ•°
    
    Args:
        host: æœåŠ¡ç«¯IP
        port: æœåŠ¡ç«¯ç«¯å£  
        directory: è¦è½¬æ¢çš„ç›®å½•
        max_workers: å¹¶å‘æ•°
        
    Returns:
        List[ConvertResult]: è½¬æ¢ç»“æœ
    """
    async with ConvertClient(host, port) as client:
        return await client.convert_directory(directory, max_workers=max_workers)


if __name__ == "__main__":
    # ç¤ºä¾‹ç”¨æ³•
    async def main():
        # åŸºç¡€ç”¨æ³•
        client = ConvertClient("192.168.1.100", 7758)
        await client.connect()
        
        # è½¬æ¢å•ä¸ªæ–‡ä»¶
        result = await client.convert_file("test.docx")
        print(f"è½¬æ¢ç»“æœ: {result}")
        
        # æ‰¹é‡è½¬æ¢ç›®å½•
        results = await client.convert_directory(
            "documents/", 
            max_workers=10,
            recursive=True
        )
        
        # æ˜¾ç¤ºå¤±è´¥çš„æ–‡ä»¶
        for result in results:
            if result.status == "error":
                print(f"âŒ {result.original_file}: {result.error}")
    
    # è¿è¡Œç¤ºä¾‹
    # asyncio.run(main())
    print("Convert2PDFå®¢æˆ·ç«¯å·²å‡†å¤‡å°±ç»ªï¼")
    print("ä½¿ç”¨æ–¹æ³•è¯·å‚è€ƒæ–‡æ¡£æˆ–è¿è¡Œ asyncio.run(main()) æŸ¥çœ‹ç¤ºä¾‹")